

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="zh-CN" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="zh-CN" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>ImageAI &mdash; ImageAI v1.0 文档</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="索引" href="genindex.html" />
    <link rel="search" title="搜索" href="search.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> ImageAI
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">ImageAI</a><ul>
<li><a class="reference internal" href="#"><strong>目录</strong></a></li>
<li><a class="reference internal" href="#"><strong>依赖性</strong></a></li>
<li><a class="reference internal" href="#"><strong>安装</strong></a></li>
<li><a class="reference internal" href="#"><strong>图像预测</strong></a></li>
<li><a class="reference internal" href="#"><strong>物体检测</strong></a></li>
<li><a class="reference internal" href="#"><strong>视频对象检测和跟踪</strong></a></li>
<li><a class="reference internal" href="#"><strong>定制模型培训</strong></a></li>
<li><a class="reference internal" href="#"><strong>自定义图像预测</strong></a></li>
<li><a class="reference internal" href="#"><strong>实时和高性能实施</strong></a></li>
<li><a class="reference internal" href="#"><strong>样本应用</strong></a></li>
<li><a class="reference internal" href="#ai"><strong>AI实践建议</strong></a></li>
<li><a class="reference internal" href="#"><strong>联系开发人员</strong></a></li>
<li><a class="reference internal" href="#"><strong>参考文献</strong></a></li>
</ul>
</li>
</ul>
</div>
            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">ImageAI</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>ImageAI</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/ImageAI.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="imageai">
<span id="imageai"></span><h1>ImageAI<a class="headerlink" href="#imageai" title="永久链接至标题">¶</a></h1>
<p>ImageAI是一个python库，旨在使开发人员能够使用简单的几行代码构建具有包含深度学习和计算机视觉功能的应用程序和系统。
这个<strong>AI Commons</strong>项目<a class="reference external" href="https://commons.specpal.science"></a><a class="reference external" href="https://commons.specpal.science">https://commons.specpal.science</a> 由<a class="reference external" href="https://twitter.com/OlafenwaMoses">Moses Olafenwa</a>和<a class="reference external" href="https://twitter.com/johnolafenwa">John Olafenwa</a>开发和维护</p>
<hr class="docutils" />
<p><strong>ImageAI</strong>以简洁为基础， 支持最先进的机器学习算法，用于图像预测，自定义图像预测，物体检测，视频检测，视频对象跟踪和图像预测培训。<strong>ImageAI</strong>目前支持使用在ImageNet-1000数据集上训练的4种不同机器学习算法进行图像预测和训练。<strong>ImageAI</strong>还支持使用在COCO数据集上训练的RetinaNet进行对象检测，视频检测和对象跟踪。
最终，<strong>ImageAI</strong>将为计算机视觉的更广泛和更专业化方面提供支持，包括但不限于特殊环境和特殊领域的图像识别。</p>
<p><strong>新版本：ImageAI 2.0.1</strong></p>
<p>新功能：</p>
<ul class="simple">
<li>使用SqueezeNet，ResNet50，InceptionV3和DenseNet121添加自定义图像预测模型训练</li>
<li>使用自定义训练模型和生成的模型类json添加自定义图像预测</li>
<li>预览版：添加视频对象检测和视频自定义对象检测（对象跟踪）</li>
<li>为所有图像预测和对象检测任务添加文件，numpy数组和流输入类型（仅用于视频检测的文件输入）</li>
<li>添加文件和numpy数组输出类型，用于图像中的对象检测和自定义对象检测</li>
<li>引入4种速度模式（“正常”，“快速”，“更快”和“最快”）进行图像预测，使预测时间在“最快”时减少50％，同时保持预测精度</li>
<li>为所有物体检测和视频物体检测任务引入5种速度模式（“正常”，“快速”，“更快”，“最快”和“闪现”），通过
“闪现”检测，检测时间缩短80％以上 准确度与’minimum_percentage_probability’保持平衡，请将该值调至较低</li>
<li>引入帧检测率，允许开发人员调整视频中的检测间隔，有利于实时/接近实时结果。</li>
</ul>
<div class="section" id="">
<span id="id1"></span><h2><a class="reference external" href="#table-of-contents"></a><strong>目录</strong><a class="headerlink" href="#" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li><a class="reference external" href="#dependencies">依赖性</a></li>
<li><a class="reference external" href="#installation">安装</a></li>
<li><a class="reference external" href="#prediction">图像预测</a></li>
<li><a class="reference external" href="#detection">物体检测</a></li>
<li><a class="reference external" href="#videodetection">视频物体检测和跟踪</a></li>
<li><a class="reference external" href="#customtraining">自定义模型训练</a></li>
<li><a class="reference external" href="#customprediction">自定义图像预测</a></li>
<li><a class="reference external" href="#sample">样本应用</a></li>
<li><a class="reference external" href="#recommendation">人工智能实践建议</a></li>
<li><a class="reference external" href="#contact">联系开发人员</a></li>
<li><a class="reference external" href="#ref">参考文献</a></li>
</ul>
</div>
<div class="section" id="">
<span id="id2"></span><h2><a class="reference external" href="#dependencies"></a><strong>依赖性</strong><a class="headerlink" href="#" title="永久链接至标题">¶</a></h2>
<p>要在应用程序开发中使用<strong>ImageAI</strong>，必须在安装<strong>ImageAI</strong>之前安装以下依赖<strong>项</strong>：</p>
<p><strong>- Python 3.5.1（及更高版本）</strong> <a class="reference external" href="https://www.python.org/downloads/">下载</a>（即将推出支持Python 2.7）</p>
<p><strong>- pip3</strong> <a class="reference external" href="https://pypi.python.org/pypi/pip">安装</a></p>
<p><strong>- Tensorflow 1.4.0（及更高版本）</strong>  <a class="reference external" href="https://www.tensorflow.org/install/install_windows">安装</a> 或 通过pip安装</p>
<p><code class="docutils literal notranslate"><span class="pre">pip3</span> <span class="pre">install</span> <span class="pre">--upgrade</span> <span class="pre">tensorflow</span></code></p>
<p><strong>- Numpy 1.13.1（及更高版本）</strong> <a class="reference external" href="https://www.scipy.org/install.html">安装</a>或 通过pip安装</p>
<p><code class="docutils literal notranslate"><span class="pre">pip3</span> <span class="pre">install</span> <span class="pre">numpy</span></code></p>
<p><strong>- SciPy 0.19.1（及更高版本）</strong> <a class="reference external" href="https://www.scipy.org/install.html">安装</a>或 通过pip安装</p>
<p><code class="docutils literal notranslate"><span class="pre">pip3</span> <span class="pre">install</span> <span class="pre">scipy</span></code></p>
<p><strong>- OpenCV</strong> <a class="reference external" href="https://pypi.python.org/pypi/opencv-python">安装</a>或 通过pip安装</p>
<p><code class="docutils literal notranslate"><span class="pre">pip3</span> <span class="pre">install</span> <span class="pre">opencv-python</span></code></p>
<p>**- pillow ** <a class="reference external" href="https://pypi.org/project/Pillow/2.2.1/">安装</a>或 通过pip安装</p>
<p><code class="docutils literal notranslate"><span class="pre">pip3</span> <span class="pre">install</span> <span class="pre">pillow</span></code></p>
<p><strong>- Matplotlib</strong> <a class="reference external" href="https://matplotlib.org/users/installing.html">安装</a>或 通过pip安装</p>
<p><code class="docutils literal notranslate"><span class="pre">pip3</span> <span class="pre">install</span> <span class="pre">matplotlib</span></code></p>
<p><strong>- h5py</strong> <a class="reference external" href="http://docs.h5py.org/en/latest/build.html">安装</a>或 通过pip安装</p>
<p><code class="docutils literal notranslate"><span class="pre">pip3</span> <span class="pre">install</span> <span class="pre">h5py</span></code></p>
<p><strong>- Keras 2.x</strong> <a class="reference external" href="https://keras.io/#installation">安装</a>或 通过pip安装</p>
<p><code class="docutils literal notranslate"><span class="pre">pip3</span> <span class="pre">install</span> <span class="pre">keras</span></code></p>
</div>
<div class="section" id="">
<span id="id3"></span><h2><a class="reference external" href="#installation"></a><strong>安装</strong><a class="headerlink" href="#" title="永久链接至标题">¶</a></h2>
<p>要安装ImageAI，请在命令行中运行下面的命令：</p>
<p><code class="docutils literal notranslate"><span class="pre">pip3</span> <span class="pre">install</span> <span class="pre">https://github.com/OlafenwaMoses/ImageAI/releases/download/2.0.1/imageai-2.0.1-py3-none-any.whl</span></code></p>
<p>或者下载Python Wheel <a class="reference external" href="https://github.com/OlafenwaMoses/ImageAI/releases/download/2.0.1/imageai-2.0.1-py3-none-any.whl"><strong>imageai-2.0.1-py3-none-any.whl</strong></a>并在命令行中指定python安装文件的路径，如下所示：</p>
<p><code class="docutils literal notranslate"><span class="pre">pip3</span> <span class="pre">install</span> <span class="pre">C:\User\MyUser\Downloads\imageai-2.0.1-py3-none-any.whl</span></code></p>
</div>
<div class="section" id="">
<span id="id4"></span><h2><a class="reference external" href="#image-prediction"></a><strong>图像预测</strong><a class="headerlink" href="#" title="永久链接至标题">¶</a></h2>
<p><strong>ImageAI</strong>提供4种不同的算法和模型类型来执行图像预测，并在ImageNet-1000数据集上进行训练。提供用于图像预测的4种算法包括<strong>SqueezeNet</strong>，<strong>ResNet</strong>，<strong>InceptionV3</strong>和<strong>DenseNet</strong>。您将在下面找到使用ResNet50模型的示例预测结果，以及图像下方的“教程和文档”链接。单击链接以查看完整的示例代码，相关说明，最佳实践指南和文档。</p>
<p><a class="reference external" href="/OlafenwaMoses/ImageAI/blob/master/images/1.jpg"><img alt="" src="https://github.com/OlafenwaMoses/ImageAI/raw/master/images/1.jpg" /></a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">convertible</span> <span class="p">:</span> <span class="mf">52.459555864334106</span>
<span class="n">sports_car</span> <span class="p">:</span> <span class="mf">37.61284649372101</span>
<span class="n">pickup</span> <span class="p">:</span> <span class="mf">3.1751200556755066</span>
<span class="n">car_wheel</span> <span class="p">:</span> <span class="mf">1.817505806684494</span>
<span class="n">minivan</span> <span class="p">:</span> <span class="mf">1.7487050965428352</span>
</pre></div>
</div>
<p><a class="reference external" href="/OlafenwaMoses/ImageAI/blob/master/imageai/Prediction">&gt;&gt;&gt;教程和文档</a></p>
</div>
<div class="section" id="">
<span id="id5"></span><h2><a class="reference external" href="#object-detection"></a><strong>物体检测</strong><a class="headerlink" href="#" title="永久链接至标题">¶</a></h2>
<p><strong>ImageAI</strong>提供了非常方便和强大的方法来对图像执行对象检测并从图像中提取每个对象。提供的物体检测类仅支持当前最先进的RetinaNet，但具有可调整最佳性能或实时处理的选项。您将在下面找到使用RetinaNet模型的示例对象检测结果，以及图像下方的“教程和文档”链接。单击链接以查看完整的示例代码，相关说明，最佳实践指南和文档。</p>
<p><strong><em>输入图像</em></strong></p>
<p><a class="reference external" href="/OlafenwaMoses/ImageAI/blob/master/images/image2.jpg"><img alt="" src="https://github.com/OlafenwaMoses/ImageAI/raw/master/images/image2.jpg" /></a></p>
<p><strong><em>输出图像</em></strong></p>
<p><a class="reference external" href="/OlafenwaMoses/ImageAI/blob/master/images/image2new.jpg"><img alt="" src="https://github.com/OlafenwaMoses/ImageAI/raw/master/images/image2new.jpg" /></a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">person</span> <span class="p">:</span> <span class="mf">91.946941614151</span>
<span class="n">person</span> <span class="p">:</span> <span class="mf">73.61021637916565</span>
<span class="n">laptop</span> <span class="p">:</span> <span class="mf">90.24320840835571</span>
<span class="n">laptop</span> <span class="p">:</span> <span class="mf">73.6881673336029</span>
<span class="n">laptop</span> <span class="p">:</span> <span class="mf">95.16398310661316</span>
<span class="n">person</span> <span class="p">:</span> <span class="mf">87.10319399833679</span>
</pre></div>
</div>
<p><a class="reference external" href="/OlafenwaMoses/ImageAI/blob/master/imageai/Detection">&gt;&gt;&gt;教程和文档</a></p>
</div>
<div class="section" id="">
<span id="id6"></span><h2><a class="reference external" href="#video-object-detection-and-tracking"></a><strong>视频对象检测和跟踪</strong><a class="headerlink" href="#" title="永久链接至标题">¶</a></h2>
<p><strong>ImageAI</strong>提供了非常方便和强大的方法来在视频中执行对象检测并跟踪特定对象。提供的视频对象检测类仅支持当前最先进的RetinaNet，但具有可调整最佳性能或实时处理的选项。您将在下面找到使用RetinaNet模型的示例对象检测结果，以及图像下方的“教程和文档”链接。单击链接可查看完整视频，示例代码，相关说明，最佳实践指南和文档。</p>
<p><em><strong>视频对象检测</strong></em></p>
<p><em>下面是检测到对象的视频的快照。</em></p>
<p><a class="reference external" href="/OlafenwaMoses/ImageAI/blob/master/images/video1.jpg"><img alt="" src="https://github.com/OlafenwaMoses/ImageAI/raw/master/images/video1.jpg" /></a></p>
<p><em><strong>视频自定义对象检测（对象跟踪）</strong></em></p>
<p><em>以下是仅检测到人，自行车和摩托车的视频的快照。</em></p>
<p><a class="reference external" href="/OlafenwaMoses/ImageAI/blob/master/images/video2.jpg"><img alt="" src="https://github.com/OlafenwaMoses/ImageAI/raw/master/images/video2.jpg" /></a></p>
<p><a class="reference external" href="/OlafenwaMoses/ImageAI/blob/master/imageai/Detection/VIDEO.md">&gt;&gt;&gt;教程和文档</a></p>
</div>
<div class="section" id="">
<span id="id7"></span><h2><a class="reference external" href="#custom-model-training-"></a><strong>定制模型培训</strong><a class="headerlink" href="#" title="永久链接至标题">¶</a></h2>
<p><strong>ImageAI</strong>为您提供了一些类和方法，用于训练可用于对您自己自定义对象执行预测的新模型。您可以使用SqueezeNet，ResNet50，InceptionV3和DenseNet在不到<strong>12</strong>行代码中训练您自定义的模型。单击图像下方的“教程和文档”链接可查看完整视频，示例代码，相关说明，最佳实践指南和文档。</p>
<p><em>来自IdenProf数据集的样本用于训练模型以预测专业人员。</em></p>
<p><a class="reference external" href="/OlafenwaMoses/ImageAI/blob/master/images/idenprof.jpg"><img alt="" src="https://github.com/OlafenwaMoses/ImageAI/raw/master/images/idenprof.jpg" /></a></p>
<p><a class="reference external" href="/OlafenwaMoses/ImageAI/blob/master/imageai/Prediction/CUSTOMTRAINING.md">&gt;&gt;&gt;教程和文档</a></p>
</div>
<div class="section" id="">
<span id="id8"></span><h2><a class="reference external" href="#custom-image-prediction-"></a><strong>自定义图像预测</strong><a class="headerlink" href="#" title="永久链接至标题">¶</a></h2>
<p><strong>ImageAI</strong>提供了类和方法，您可以自己使用<strong>ImageAI</strong> Model Training类训练的模型预测您自定义的对象。您可以使用SqueezeNet，ResNet50，InceptionV3和DenseNet的自定义模型以及包含自定义对象名称映射的JSON文件。您将在图像下方找到“教程和文档”链接。单击链接可查看示例代码，相关说明，最佳实践指南和文档示例指南。</p>
<p><em>从IdenProf训练的样本模型预测，用于预测专业人员</em></p>
<p><a class="reference external" href="/OlafenwaMoses/ImageAI/blob/master/images/4.jpg"><img alt="" src="https://github.com/OlafenwaMoses/ImageAI/raw/master/images/4.jpg" /></a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mechanic</span> <span class="p">:</span> <span class="mf">76.82620286941528</span>
<span class="n">chef</span> <span class="p">:</span> <span class="mf">10.106072574853897</span>
<span class="n">waiter</span> <span class="p">:</span> <span class="mf">4.036874696612358</span>
<span class="n">police</span> <span class="p">:</span> <span class="mf">2.6663416996598244</span>
<span class="n">pilot</span> <span class="p">:</span> <span class="mf">2.239348366856575</span>
</pre></div>
</div>
<p><a class="reference external" href="/OlafenwaMoses/ImageAI/blob/master/imageai/Prediction/CUSTOMPREDICTION.md">&gt;&gt;&gt;教程和文档</a></p>
</div>
<div class="section" id="">
<span id="id9"></span><h2><a class="reference external" href="#real-time-and-high-perfomance-implementation"></a><strong>实时和高性能实施</strong><a class="headerlink" href="#" title="永久链接至标题">¶</a></h2>
<p><strong>ImageAI</strong>提供了最先进的计算机视觉技术的抽象和方便的实现。所有<strong>ImageAI</strong>实现和代码都可以在具有中等CPU核心数的计算机系统上运行。但是，CPU上的图像预测，对象检测等操作的处理速度很慢，不适合实时应用。要以高性能执行实时计算机视觉操作，您需要使用支持GPU的技术。</p>
<p><strong>ImageAI</strong>使用Tensorflow进行计算机视觉操作。Tensorflow支持CPU和GPU（特别是NVIDIA GPU），用于机器学习和人工智能算法的实施。要使用支持GPU的Tensorflow，请点击以下链接：</p>
<ul>
<li><p class="first">FOR WINDOWS</p>
<p><a class="reference external" href="https://www.tensorflow.org/install/install_windows">https://www.tensorflow.org/install/install_windows</a></p>
</li>
<li><p class="first">FOR macOS</p>
<p><a class="reference external" href="https://www.tensorflow.org/install/install_mac"></a><a class="reference external" href="https://www.tensorflow.org/install/install_mac">https://www.tensorflow.org/install/install_mac</a></p>
</li>
<li><p class="first">FOR UBUNTU</p>
<p><a class="reference external" href="https://www.tensorflow.org/install/install_linux"></a><a class="reference external" href="https://www.tensorflow.org/install/install_linux">https://www.tensorflow.org/install/install_linux</a></p>
</li>
</ul>
</div>
<div class="section" id="">
<span id="id10"></span><h2><a class="reference external" href="#sample-applications"></a><strong>样本应用</strong><a class="headerlink" href="#" title="永久链接至标题">¶</a></h2>
<p>作为使用ImageAI可以做什么的演示，我们使用<strong>ImageAI</strong>和UI框架<strong>Kivy</strong>为Windows构建了一个完整的人工智能照片库，名为<strong>IntelliP</strong>。点击此 <a class="reference external" href="https://github.com/OlafenwaMoses/IntelliP">链接</a>下载应用程序页面及其源代码。<a class="reference external" href="https://github.com/OlafenwaMoses/IntelliP"></a></p>
<p>我们也欢迎您提交应用程序和系统构建，并由ImageAI提供在此的列表。如果您需要此处列出的ImageAI驱动开发，您可以通过下面的<a class="reference external" href="#contact">联系方式</a>与我们<a class="reference external" href="#contact">联系</a>。</p>
</div>
<div class="section" id="ai">
<span id="ai"></span><h2><a class="reference external" href="#ai-practice-recommendations"></a><strong>AI实践建议</strong><a class="headerlink" href="#ai" title="永久链接至标题">¶</a></h2>
<p>对于任何有兴趣建立人工智能系统并将其用于商业，经济，社会和研究目的的人来说，至关重要的是该人员知道这些技术的使用可能产生的积极，消极和前所未有的影响。他们还必须了解经验丰富的行业专家建议的方法和实践，以确保人工智能的每次使用都为人类带来整体利益。因此，我们建议所有希望使用ImageAI和其他人工智能工具和资源的人阅读微软2018年1月出版的题为“未来计算：人工智能及其在社会中的作用”的出版物。请点击以下链接下载该出版物。</p>
<p><a class="reference external" href="https://blogs.microsoft.com/blog/2018/01/17/future-computed-artificial-intelligence-role-society/"></a><a class="reference external" href="https://blogs.microsoft.com/blog/2018/01/17/future-computed-artificial-intelligence-role-society/">https://blogs.microsoft.com/blog/2018/01/17/future-computed-artificial-intelligence-role-society/</a></p>
</div>
<div class="section" id="">
<span id="id11"></span><h2><a class="reference external" href="#contact-developers"></a><strong>联系开发人员</strong><a class="headerlink" href="#" title="永久链接至标题">¶</a></h2>
<p><strong>Moses Olafenwa</strong></p>
<p><em>Email:</em> <a class="reference external" href="mailto:guymodscientist&#37;&#52;&#48;gmail&#46;com">guymodscientist<span>&#64;</span>gmail<span>&#46;</span>com</a></p>
<p><em>Website:</em> <a class="reference external" href="https://moses.specpal.science">https://moses.specpal.science</a></p>
<p><em>Twitter:</em> <a class="reference external" href="https://twitter.com/OlafenwaMoses">&#64;OlafenwaMoses</a></p>
<p><em>Medium :</em> <a class="reference external" href="https://medium.com/&#64;guymodscientist">&#64;guymodscientist</a></p>
<p><em>Facebook :</em> <a class="reference external" href="https://facebook.com/moses.olafenwa">moses.olafenwa</a></p>
<p><strong>John Olafenwa</strong></p>
<p><em>Email:</em> <a class="reference external" href="mailto:johnolafenwa&#37;&#52;&#48;gmail&#46;com">johnolafenwa<span>&#64;</span>gmail<span>&#46;</span>com</a></p>
<p><em>Website:</em> <a class="reference external" href="https://john.specpal.science">https://john.specpal.science</a></p>
<p><em>Twitter:</em> <a class="reference external" href="https://twitter.com/johnolafenwa">&#64;johnolafenwa</a></p>
<p><em>Medium :</em> <a class="reference external" href="https://medium.com/&#64;johnolafenwa">&#64;johnolafenwa</a></p>
<p><em>Facebook :</em> <a class="reference external" href="https://facebook.com/olafenwajohn">olafenwajohn</a></p>
</div>
<div class="section" id="">
<span id="id12"></span><h2><a class="reference external" href="#references"></a><strong>参考文献</strong><a class="headerlink" href="#" title="永久链接至标题">¶</a></h2>
<ol>
<li><p class="first">Somshubra Majumdar, DenseNet Implementation of the paper, Densely Connected Convolutional Networks in Keras</p>
<p><a class="reference external" href="https://github.com/titu1994/DenseNet/"></a><a class="reference external" href="https://github.com/titu1994/DenseNet/">https://github.com/titu1994/DenseNet/</a></p>
</li>
<li><p class="first">Broad Institute of MIT and Harvard, Keras package for deep residual networks</p>
<p><a class="reference external" href="https://github.com/broadinstitute/keras-resnet"></a><a class="reference external" href="https://github.com/broadinstitute/keras-resnet">https://github.com/broadinstitute/keras-resnet</a></p>
</li>
<li><p class="first">Fizyr, Keras implementation of RetinaNet object detection</p>
<p><a class="reference external" href="https://github.com/fizyr/keras-retinanet"></a><a class="reference external" href="https://github.com/fizyr/keras-retinanet">https://github.com/fizyr/keras-retinanet</a></p>
</li>
<li><p class="first">Francois Chollet, Keras code and weights files for popular deeplearning models</p>
<p><a class="reference external" href="https://github.com/fchollet/deep-learning-models"></a><a class="reference external" href="https://github.com/fchollet/deep-learning-models">https://github.com/fchollet/deep-learning-models</a></p>
</li>
<li><p class="first">Forrest N. et al, SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and &lt;0.5MB model size</p>
<p><a class="reference external" href="https://arxiv.org/abs/1602.07360"></a><a class="reference external" href="https://arxiv.org/abs/1602.07360">https://arxiv.org/abs/1602.07360</a></p>
</li>
<li><p class="first">Kaiming H. et al, Deep Residual Learning for Image Recognition</p>
<p><a class="reference external" href="https://arxiv.org/abs/1512.03385"></a><a class="reference external" href="https://arxiv.org/abs/1512.03385">https://arxiv.org/abs/1512.03385</a></p>
</li>
<li><p class="first">Szegedy. et al, Rethinking the Inception Architecture for Computer Vision</p>
<p><a class="reference external" href="https://arxiv.org/abs/1512.00567"></a><a class="reference external" href="https://arxiv.org/abs/1512.00567">https://arxiv.org/abs/1512.00567</a></p>
</li>
<li><p class="first">Gao. et al, Densely Connected Convolutional Networks</p>
<p><a class="reference external" href="https://arxiv.org/abs/1608.06993"></a><a class="reference external" href="https://arxiv.org/abs/1608.06993">https://arxiv.org/abs/1608.06993</a></p>
</li>
<li><p class="first">Tsung-Yi. et al, Focal Loss for Dense Object Detection</p>
<p><a class="reference external" href="https://arxiv.org/abs/1708.02002"></a><a class="reference external" href="https://arxiv.org/abs/1708.02002">https://arxiv.org/abs/1708.02002</a></p>
</li>
<li><p class="first">O Russakovsky et al, ImageNet Large Scale Visual Recognition Challenge</p>
</li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[](</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arxiv</span><span class="o">.</span><span class="n">org</span><span class="o">/</span><span class="nb">abs</span><span class="o">/</span><span class="mf">1409.0575</span><span class="p">)[</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arxiv</span><span class="o">.</span><span class="n">org</span><span class="o">/</span><span class="nb">abs</span><span class="o">/</span><span class="mf">1409.0575</span><span class="p">](</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arxiv</span><span class="o">.</span><span class="n">org</span><span class="o">/</span><span class="nb">abs</span><span class="o">/</span><span class="mf">1409.0575</span><span class="p">)</span>
</pre></div>
</div>
<ol class="simple">
<li>TY Lin et al, Microsoft COCO: Common Objects in Context</li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[](</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arxiv</span><span class="o">.</span><span class="n">org</span><span class="o">/</span><span class="nb">abs</span><span class="o">/</span><span class="mf">1405.0312</span><span class="p">)[</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arxiv</span><span class="o">.</span><span class="n">org</span><span class="o">/</span><span class="nb">abs</span><span class="o">/</span><span class="mf">1405.0312</span><span class="p">](</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arxiv</span><span class="o">.</span><span class="n">org</span><span class="o">/</span><span class="nb">abs</span><span class="o">/</span><span class="mf">1405.0312</span><span class="p">)</span>
</pre></div>
</div>
<ol class="simple">
<li>Moses &amp; John Olafenwa, A collection of images of identifiable professionals.</li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[](</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">OlafenwaMoses</span><span class="o">/</span><span class="n">IdenProf</span><span class="p">)[</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">OlafenwaMoses</span><span class="o">/</span><span class="n">IdenProf</span><span class="p">](</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">OlafenwaMoses</span><span class="o">/</span><span class="n">IdenProf</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, kangvcar.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'v1.0',
            LANGUAGE:'zh_CN',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="_static/translations.js"></script>

  

  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>